CALCULATION OF TIME COMPLEXITY:

Suppose there are two statements. First is 

a=b*c.

Now multiplication is a tedious process because you  add a number over and over again to get the answer.
Second statement is

 a=b+c. 
This is simple addition so it is supposed to be faster than multiplication.

 Now the thing is, we don't know how much time exactly each statement would take. But we know one thing for sure that these are really small operations and the computer can do it in constant time. So we assign constants to each statement

Okay forget insertion sort for now, let's see an easy example for now. Linear search.


for(int i=0;i<n;i++)

{

if(arr[i] == ans)

counter = 1;

}

How many times will each statement run?

So,
for(int i=0;i<n;i++)// (n+1)c1 time
{

if(arr[i] == ans && counter ==0) // c2 time

counter = 1; // nc3 time
}
SO, total time taken is (n+1)c1+c2+nc3
=n(c1+c3)+c1+c2

Linear Search:
for(int i=0;i<n;i++)// (n+1)c1 time
{

if(arr[i] == ans) // nc2 time

break; // nc3 time
}

So for linear search 

Best case - O(1)

Average case- O(n)

Worst case- O(n)

int a = 0; 

for (i = 0; i < N; i++) { 
   // (N+1)c1 
   for (j = N; j > i; j--) { 
// (N+1)^2c2
     a = a + i + j; 
    N^2c3
}
 
}

Total time= N^2

int a = 0, i = N; 

while (i > 0) { 
  
  a += i; 
  
  i /= 2;
 
}
You are given a number N. We want to know how many times the given number is divisible by 2.
Therefore, N/2^x = 1
then x= log N/log 2
     x= log N(base2)
we don't say logN base2 every time. We just say logN, base 2 is understood
 the equation : (log N+1)c1+ Log n/4+Log n/4

time complexity= log N

